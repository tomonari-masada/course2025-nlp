{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course2025-nlp/blob/main/10_finetuning_LLMs_with_LoRA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezyT_wTQKCDI"
      },
      "source": [
        "# LoRAを使ったLLMのfine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jn_2vVdgKCDM"
      },
      "source": [
        "## 準備"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Js_2y3RFpQ6K"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import load_from_disk\n",
        "import evaluate\n",
        "from transformers import set_seed, AutoTokenizer, AutoModelForSequenceClassification\n",
        "from peft import get_peft_model, LoraConfig, TaskType, PeftModel\n",
        "\n",
        "set_seed(0)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O838f1_RKCDO"
      },
      "source": [
        "## データセット"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsaMG-dIKCDP"
      },
      "source": [
        "* livedoorニュースコーパスを使う。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdEjVRZPqOfz"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/tomonari-masada/course2025-nlp/raw/refs/heads/main/livedoor_ds.tar.gz\n",
        "!tar zxf livedoor_ds.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxZLq3TK5GLj"
      },
      "outputs": [],
      "source": [
        "ds = load_from_disk(\"livedoor_ds\")\n",
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBksh8An5cPK"
      },
      "outputs": [],
      "source": [
        "category_names = [\n",
        "    'movie-enter',\n",
        "    'it-life-hack',\n",
        "    'kaden-channel',\n",
        "    'topic-news',\n",
        "    'livedoor-homme',\n",
        "    'peachy',\n",
        "    'sports-watch',\n",
        "    'dokujo-tsushin',\n",
        "    'smax',\n",
        "]\n",
        "\n",
        "num_labels = len(set(ds[\"train\"][\"category\"]))\n",
        "num_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCRtmdWSKCDR"
      },
      "source": [
        "## LLMの選定"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzsLmkGDKCDR"
      },
      "source": [
        "* ここでは`intfloat/multilingual-e5-large-instruct`を使う。\n",
        "  * 他のLLMでも、コードは同様に書けばよい。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JimdaUZdKCDR"
      },
      "source": [
        "## トークナイザの取得"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5zsXVlJ5kB5"
      },
      "outputs": [],
      "source": [
        "model_name = \"intfloat/multilingual-e5-large-instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DglhC8FKCDS"
      },
      "source": [
        "* collate関数\n",
        "  * あとでDataLoaderに使う。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0yQ_CaHKCDS"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    texts = []\n",
        "    labels = []\n",
        "    for sample in batch:\n",
        "        texts.append(sample[\"content\"])\n",
        "        labels.append(sample[\"category\"])\n",
        "    tokenized = tokenizer(\n",
        "        texts,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=tokenizer.model_max_length,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    return tokenized.to(device), torch.tensor(labels).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aisD6pPONXe0"
      },
      "source": [
        "## モデルの取得"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6a8M0UGKeQ9f"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=num_labels,\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KN2JDR5lKCDS"
      },
      "source": [
        "## LoRA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXsZznMjKCDS"
      },
      "source": [
        "### LLMの構造の確認\n",
        "* どの部分をLoRAアダプタで更新するかを決める。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eiu0G08KCDS"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9094y5dgKCDS"
      },
      "source": [
        "### LoRAの設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsoJGFayKCDT"
      },
      "outputs": [],
      "source": [
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS,\n",
        "    inference_mode=False,\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        "    target_modules=[\"word_embeddings\", \"query\", \"value\", \"key\", \"dense\"],\n",
        ")\n",
        "lora_model = get_peft_model(model, lora_config)\n",
        "lora_model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eFgzxtkKCDT"
      },
      "outputs": [],
      "source": [
        "lora_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zC5N_HRRKCDT"
      },
      "source": [
        "## trainingのためのヘルパ関数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1C4ATmZ6KCDT"
      },
      "outputs": [],
      "source": [
        "def train(model, dataloader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_acc, total_loss, total_count = 0, 0, 0\n",
        "    log_interval = 10\n",
        "    num_of_seen_batches = 0\n",
        "\n",
        "    start_time = time.time()\n",
        "    for tokenized, labels in tqdm(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(**tokenized).logits\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    total_acc += (logits.argmax(1) == labels).sum().item()\n",
        "    total_loss += loss.item() * labels.size(0)\n",
        "    total_count += labels.size(0)\n",
        "    num_of_seen_batches += 1\n",
        "    if num_of_seen_batches % log_interval == 0 and num_of_seen_batches > 0:\n",
        "        print(\n",
        "            f\"||| {num_of_seen_batches:5d}/{len(dataloader):5d} batches | \"\n",
        "            f\"time: {time.time() - start_time:5.2f}s | \"\n",
        "            f\"accuracy {total_acc / total_count:8.3f} | \"\n",
        "            f\"loss {total_loss / total_count:8.3f}\"\n",
        "        )\n",
        "        total_acc, total_loss, total_count = 0, 0, 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YypUSeDiKCDT"
      },
      "source": [
        "## 評価のためのヘルパ関数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_EhY8lVKCDT"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    total_acc, total_count = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for tokenized, labels in tqdm(dataloader):\n",
        "            logits = model(**tokenized).logits\n",
        "            loss = criterion(logits, labels)\n",
        "            total_acc += (logits.argmax(1) == labels).sum().item()\n",
        "            total_count += labels.size(0)\n",
        "    return total_acc / total_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWUX7S9PKCDT"
      },
      "source": [
        "## DataLoaderの作成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf9S9GKkKCDT"
      },
      "source": [
        "* バッチサイズはGPUのメモリ量に応じて決める。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLM4WgMKKCDT"
      },
      "outputs": [],
      "source": [
        "batch_size = 4\n",
        "\n",
        "train_dataloader = DataLoader(ds[\"train\"], batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "valid_dataloader = DataLoader(ds[\"validation\"], batch_size=batch_size, collate_fn=collate_fn)\n",
        "test_dataloader = DataLoader(ds[\"test\"], batch_size=batch_size, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x13PSO2KKCDT"
      },
      "source": [
        "## fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6JFST3pKCDU"
      },
      "source": [
        "### trainingの設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfXiJx9qKCDU"
      },
      "outputs": [],
      "source": [
        "epochs = 3\n",
        "learning_rate = 1e-4\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(lora_model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IX-0mWPXKCDU"
      },
      "source": [
        "### LoRAのtraining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkbefXghKCDU"
      },
      "outputs": [],
      "source": [
        "for epoch in range(epochs):\n",
        "    epoch_start_time = time.time()\n",
        "    train(lora_model, train_dataloader, optimizer, criterion)\n",
        "    accu_val = evaluate(lora_model, valid_dataloader, criterion)\n",
        "    print(\"-\" * 59)\n",
        "    elapsed = time.time() - epoch_start_time\n",
        "    print(\n",
        "        f\"| end of epoch {epoch+1:3d} | \"\n",
        "        f\"time: {elapsed:5.2f}s | \"\n",
        "        f\"lr = {optimizer.param_groups[0]['lr']:.3f} | \"\n",
        "        f\"validation accuracy {accu_val:8.3f}\"\n",
        "    )\n",
        "    print(\"-\" * 82)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQ4miB2NKCDU"
      },
      "source": [
        "## test setでの評価"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVrMqmBiKCDU"
      },
      "outputs": [],
      "source": [
        "accu_val = evaluate(lora_model, test_dataloader, criterion)\n",
        "print(f\"test accuracy {accu_val:8.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQEKv9MNKCDU"
      },
      "source": [
        "## LoRAの保存"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izEjUdsoKCDU"
      },
      "outputs": [],
      "source": [
        "adapter_path = \"lora_finetuned_model\"\n",
        "lora_model.save_pretrained(adapter_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcIhd6FJKCDU"
      },
      "source": [
        "## LoRAの読み込み"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vxQugv-KCDZ"
      },
      "source": [
        "* 下のセルでは、あらかじめ元のモデルは読み込んであると想定している。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSflLzMAKCDZ"
      },
      "outputs": [],
      "source": [
        "adapter_path = \"lora_finetuned_model\"\n",
        "lora_model = PeftModel.from_pretrained(model, adapter_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dorVtN8hKCDZ"
      },
      "outputs": [],
      "source": [
        "accu_val = evaluate(lora_model, test_dataloader, criterion)\n",
        "print(f\"test accuracy {accu_val:8.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Irud7fS8KCDZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "nlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}