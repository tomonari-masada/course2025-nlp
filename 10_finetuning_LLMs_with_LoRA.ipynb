{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course2025-nlp/blob/main/10_finetuning_LLMs_with_LoRA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQN7m3MDS_hS"
      },
      "source": [
        "# LoRAを使ったLLMのfine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvZ9ZK9GS_hV"
      },
      "source": [
        "## 準備"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Js_2y3RFpQ6K"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import load_from_disk\n",
        "from transformers import set_seed, AutoTokenizer, AutoModelForSequenceClassification\n",
        "from peft import get_peft_model, LoraConfig, TaskType, PeftModel\n",
        "\n",
        "set_seed(0)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyKFUi_IS_hX"
      },
      "source": [
        "## データセット"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcas34f5S_hX"
      },
      "source": [
        "* livedoorニュースコーパスを使う。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdEjVRZPqOfz"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/tomonari-masada/course2025-nlp/raw/refs/heads/main/livedoor_ds.tar.gz\n",
        "!tar zxf livedoor_ds.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxZLq3TK5GLj"
      },
      "outputs": [],
      "source": [
        "ds = load_from_disk(\"livedoor_ds\")\n",
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBksh8An5cPK"
      },
      "outputs": [],
      "source": [
        "category_names = [\n",
        "    'movie-enter',\n",
        "    'it-life-hack',\n",
        "    'kaden-channel',\n",
        "    'topic-news',\n",
        "    'livedoor-homme',\n",
        "    'peachy',\n",
        "    'sports-watch',\n",
        "    'dokujo-tsushin',\n",
        "    'smax',\n",
        "]\n",
        "\n",
        "num_labels = len(set(ds[\"train\"][\"category\"]))\n",
        "print(f\"Number of labels: {num_labels}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTtnsvvMS_hY"
      },
      "source": [
        "## LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuJLt9AdS_hY"
      },
      "source": [
        "* ここでは`intfloat/multilingual-e5-large-instruct`を使う。\n",
        "  * 他のLLMでも、コードは同様に書けばよい。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z35XRssS_hY"
      },
      "source": [
        "## トークナイザの取得"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5zsXVlJ5kB5"
      },
      "outputs": [],
      "source": [
        "model_name = \"intfloat/multilingual-e5-large-instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDGx3WcHS_hZ"
      },
      "source": [
        "* collate関数\n",
        "  * あとでDataLoaderに使う。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnQ2tffOS_hZ"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    texts = []\n",
        "    labels = []\n",
        "    for sample in batch:\n",
        "        texts.append(sample[\"content\"])\n",
        "        labels.append(sample[\"category\"])\n",
        "    tokenized = tokenizer(texts, padding=True, truncation=True, max_length=tokenizer.model_max_length, return_tensors=\"pt\")\n",
        "    return tokenized.to(device), torch.tensor(labels).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aisD6pPONXe0"
      },
      "source": [
        "## モデルの取得"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6a8M0UGKeQ9f"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIxZHs32S_hZ"
      },
      "source": [
        "## LoRA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVSocg6QS_hZ"
      },
      "source": [
        "### LLMの構造の確認\n",
        "* どの部分をLoRAアダプタで更新するかを決める。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WewmwhLuS_hZ"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4AnZzMtS_hZ"
      },
      "source": [
        "### LoRAの設定"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lt82MyLoS_hZ"
      },
      "source": [
        "* https://huggingface.co/docs/peft/en/package_reference/lora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqX0octvS_ha"
      },
      "outputs": [],
      "source": [
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_CLS,\n",
        "    inference_mode=False, # trainingをするのでFalseに設定\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        "    target_modules=[\"word_embeddings\", \"query\", \"value\", \"key\", \"dense\"],\n",
        ")\n",
        "lora_model = get_peft_model(model, lora_config)\n",
        "lora_model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFrt0hrOS_ha"
      },
      "outputs": [],
      "source": [
        "lora_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iN4h-1FtS_ha"
      },
      "source": [
        "* `requires_grad`がTrueになっているパラメータを調べてみる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zJmkuVfS_ha"
      },
      "outputs": [],
      "source": [
        "for name, param in lora_model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name, param.data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVay2lTCS_ha"
      },
      "source": [
        "## 評価のためのヘルパ関数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoT5dsRvS_ha"
      },
      "outputs": [],
      "source": [
        "def evaluation(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    total_acc, total_count = 0, 0\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for tokenized, labels in tqdm(dataloader):\n",
        "            logits = model(**tokenized).logits\n",
        "            loss = criterion(logits, labels)\n",
        "            total_loss += loss.item() * labels.size(0)\n",
        "            total_acc += (logits.argmax(1) == labels).sum().item()\n",
        "            total_count += labels.size(0)\n",
        "    return total_loss / total_count, total_acc / total_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8_M5Da9S_ha"
      },
      "source": [
        "## trainingのためのヘルパ関数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQpKbrrhS_ha"
      },
      "outputs": [],
      "source": [
        "def train(model, dataloader, eval_dataloader, optimizer, criterion, gradient_accumulation_steps=1, eval_interval=100, log_interval=50):\n",
        "    model.train()\n",
        "    total_acc, total_loss, total_count = 0, 0, 0\n",
        "\n",
        "    start_time = time.time()\n",
        "    num_of_seen_batches = 0\n",
        "    for tokenized, labels in tqdm(dataloader):\n",
        "        num_of_seen_batches += 1\n",
        "        logits = model(**tokenized).logits\n",
        "        loss = criterion(logits, labels) / gradient_accumulation_steps\n",
        "        loss.backward()\n",
        "\n",
        "        total_acc += (logits.argmax(1) == labels).sum().item()\n",
        "        total_loss += loss.item() * labels.size(0)\n",
        "        total_count += labels.size(0)\n",
        "\n",
        "        if num_of_seen_batches % gradient_accumulation_steps == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        if log_interval > 0 and num_of_seen_batches % log_interval == 0:\n",
        "            print(\n",
        "                f\"||| {num_of_seen_batches:5d}/{len(dataloader):5d} batches | \"\n",
        "                f\"time: {time.time() - start_time:5.2f}s | \"\n",
        "                f\"accuracy {total_acc / total_count:8.3f} | \"\n",
        "                f\"loss {total_loss / total_count:8.3f}\",\n",
        "                flush=True,\n",
        "            )\n",
        "            total_acc, total_loss, total_count = 0, 0, 0\n",
        "\n",
        "        if eval_interval > 0 and num_of_seen_batches % eval_interval == 0:\n",
        "            val_loss, val_accuracy = evaluation(model, eval_dataloader, criterion)\n",
        "            print(\"-\" * 59)\n",
        "            print(\n",
        "                f\"| validation loss {val_loss:8.3f} | \"\n",
        "                f\"validation accuracy {val_accuracy:8.3f}\"\n",
        "            )\n",
        "            print(\"-\" * 82)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fldPLLuuS_ha"
      },
      "source": [
        "## DataLoaderの作成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBpQizUrS_ha"
      },
      "source": [
        "* バッチサイズはGPUのメモリ量に応じて決める。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWf-RiAMS_ha"
      },
      "outputs": [],
      "source": [
        "batch_size = 4\n",
        "\n",
        "train_dataloader = DataLoader(ds[\"train\"], batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "valid_dataloader = DataLoader(ds[\"validation\"], batch_size=batch_size, collate_fn=collate_fn)\n",
        "test_dataloader = DataLoader(ds[\"test\"], batch_size=batch_size, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cakqAgrBS_ha"
      },
      "source": [
        "## fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_0GHuauS_hb"
      },
      "source": [
        "### trainingの設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8NM9JKyS_hb"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-4\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(lora_model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHie2BA-S_hb"
      },
      "source": [
        "### LoRAのtraining"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJToLd3_S_hb"
      },
      "source": [
        "* RTX4090で実行すると、6分弱でvalidation accuracyが0.95を超えます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KD76I9frS_hb"
      },
      "outputs": [],
      "source": [
        "epochs = 3 # 実際はもう少し多めに回す\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    epoch_start_time = time.time()\n",
        "    train(lora_model, train_dataloader, valid_dataloader, optimizer, criterion, gradient_accumulation_steps=8, log_interval=50, eval_interval=200)\n",
        "    print(\"-\" * 59)\n",
        "    elapsed = time.time() - epoch_start_time\n",
        "    print(\n",
        "        f\"| end of epoch {epoch+1:3d} | \"\n",
        "        f\"time: {elapsed:5.2f}s | \",\n",
        "        flush=True\n",
        "    )\n",
        "    print(\"-\" * 82)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7Jxb_ApS_hb"
      },
      "source": [
        "## test setでの評価"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6kYjFijS_hg"
      },
      "outputs": [],
      "source": [
        "loss, accu_val = evaluation(lora_model, test_dataloader, criterion)\n",
        "print(f\"test loss {loss:8.3f} | test accuracy {accu_val:8.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmjV73RjS_hg"
      },
      "source": [
        "## LoRAの保存"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Mbl89LfS_hg"
      },
      "outputs": [],
      "source": [
        "adapter_path = \"lora_finetuned_model\"\n",
        "lora_model.save_pretrained(adapter_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUzsx-oJS_hg"
      },
      "source": [
        "## LoRAの読み込み"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmxMI9uXS_hg"
      },
      "source": [
        "* モデルを一旦削除する。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_nWqv0pS_hg"
      },
      "outputs": [],
      "source": [
        "del lora_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oibI1otnS_hg"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypdWvtYlS_hg"
      },
      "source": [
        "* モデルを読み込み直してから、学習済みのLoRAを適用する。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2cZaFDAS_hg"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels).to(device)\n",
        "adapter_path = \"lora_finetuned_model\"\n",
        "lora_model = PeftModel.from_pretrained(model, adapter_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Xt9seSRS_hg"
      },
      "source": [
        "* 先ほどと同じ評価値が出るはず。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUrsQ9O9S_hg"
      },
      "outputs": [],
      "source": [
        "loss, accu_val = evaluation(lora_model, test_dataloader, criterion)\n",
        "print(f\"test loss {loss:8.3f} | test accuracy {accu_val:8.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0BAEOvlS_hh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "nlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}