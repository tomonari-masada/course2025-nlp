{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course2025-nlp/blob/main/11_superposition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b0e306a",
      "metadata": {
        "id": "0b0e306a"
      },
      "source": [
        "# Toy Models of Superposition\n",
        "https://transformer-circuits.pub/2022/toy_model/\n",
        "\n",
        "* このWebページのSection 2までを今回扱う。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ニューラルネットワークによって得られる特徴量\n",
        "* ニューラルネットワーク(NN) は、データの特徴量を自動的に抽出してくれると考えられている。\n",
        "  * 手動での特徴量エンジニアリングを不要にしてくれたことが、NNの大きな貢献でもある。\n",
        "* 例えば、多層パーセプトロンの特定の層に含まれる複数のニューロンを考える。\n",
        "* これらのニューロンは、それぞれが別々の特徴量（例: 赤い色、左向きの曲線、犬の鼻、等）に反応すると考えていいのだろうか？\n",
        "* そうとは限らないのでは？という考え方が、ある2022年の論文で提示されている。（上掲リンク先）\n",
        "  * 多層パーセプトロンの特定の層のサイズを$m$とする。\n",
        "  * サンプルをNNに入力すると、この層のニューロンの出力として$m$次元ベクトルが得られる。\n",
        "  * この$m$次元ベクトルは、より高次元の$n$次元空間（$n \\gg m$）の空間の直交基底を使って初めて表現できるような情報を含みうるということが、上掲論文では主張されている。\n",
        "  * より高次元の空間でないと表現できない情報が、重ね合わされて（superposeされて）隠れベクトルにおいて表現されている、と主張されているのである。\n",
        "  * つまり、NNは、場合によっては、ニューロンの個数よりも多い特徴量を表現していることがありうる、ということ。"
      ],
      "metadata": {
        "id": "mf4YtV-QUCw5"
      },
      "id": "mf4YtV-QUCw5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 以下のコードで何をしようとしているか\n",
        "* 今回は、低い次元の空間のベクトルの集合が、その次元よりも高次元の情報を表現しうる（representしうる）ことを確認する。\n",
        "  * 非常に簡単なモデルと、合成データとを使った、簡単な数値実験によって、このことを確認する。"
      ],
      "metadata": {
        "id": "S4zjeW6FW8xs"
      },
      "id": "S4zjeW6FW8xs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 数値実験の概要\n",
        "* 例えば5次元のランダムなベクトルを、たくさん合成する。\n",
        "  * ただし、これらはスパースなベクトルとする。\n",
        "  * つまり、まずは一様乱数でベクトルの中身を埋めたあと、一定の確率でそれらを0にする。\n",
        "  * これは、NNに入力される様々なサンプルが、限られた個数の特徴量しか持ち合わせていないことに対応している。\n",
        "  * もちろん、あらゆるサンプルにわたって、そこに現れる特徴量の種類を調べると、その総数は非常に多いはずである。\n",
        "  * しかし、個々のサンプルで見れば、わずかな数の特徴量しかそこには現れていないはずである。\n",
        "* これら多数の5次元ベクトルを、特殊な方法で、例えば2次元に次元圧縮する。\n",
        "  * すると、元の5次元ベクトルのsparsityが非常に高い場合、2次元空間に2個より多い「基底のようなもの」が計算されてくる。\n",
        "  * そして、次元圧縮された2次元ベクトルは、これら、2個より多い「基底のようなもの」で表現されると考えることができる。"
      ],
      "metadata": {
        "id": "VkGTBpXhYMj_"
      },
      "id": "VkGTBpXhYMj_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 根拠: Johnson-Lindenstrauss lemma\n",
        "* $N$個の$n$次元ベクトルの集合$X$を考える。\n",
        "* $n$次元ベクトルを、より低い$m$次元のベクトルへと変換する線形写像は、いろいろありうるが・・・\n",
        "  * $m \\times n$の行列を持ってくればいいだけ。\n",
        "* 実は、元の$n$次元空間でのベクトル間のユークリッド距離を\"ほとんど変えない\"線形写像が存在する。\n",
        "* しかも、$m$は$\\log(N)$のオーダまで小さくできる。\n",
        "  * このオーダよりも小さい次元にすることはできない。\n",
        "  * 元の空間の次元$n$ではなく、ベクトルの個数$N$に依存する量であることに注意。\n"
      ],
      "metadata": {
        "id": "HbhVtSmBSSGS"
      },
      "id": "HbhVtSmBSSGS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af826785",
      "metadata": {
        "id": "af826785"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 高次元の特徴量の低次元表現を求めるためのモデル"
      ],
      "metadata": {
        "id": "wAVi2o0fUqRL"
      },
      "id": "wAVi2o0fUqRL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a176ce10",
      "metadata": {
        "id": "a176ce10"
      },
      "outputs": [],
      "source": [
        "class SuperpositionModel(nn.Module):\n",
        "    def __init__(self, dim_n, dim_m):\n",
        "        super(SuperpositionModel, self).__init__()\n",
        "        self.dim_n = dim_n\n",
        "        self.dim_m = dim_m\n",
        "        self.W = nn.Parameter(torch.randn(dim_n, dim_m))\n",
        "        self.b = nn.Parameter(torch.zeros(dim_n))\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = torch.matmul(x, self.W)\n",
        "        x_reconstructed = torch.relu(torch.matmul(h, self.W.t()) + self.b)\n",
        "        return x_reconstructed, h"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 高次元（$n$次元）の特徴量がsparseだと・・・\n",
        "  * 同時に発火する特徴量が、少ない個数に限られることになる。\n",
        "  * すると、ニューロン出力の空間の次元$m$が$n$より小さくても・・・\n",
        "  * 高次元特徴量の$m$次元表現によって、それを再構成するときに・・・\n",
        "  * 再構成のやり方が何通りもある、ということはなくなる。\n",
        "  * （直交基底であれば、再構成のやり方は一通りしかない。）"
      ],
      "metadata": {
        "id": "WGHyNFXYOns9"
      },
      "id": "WGHyNFXYOns9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ということは、合成データを非常にスパースなベクトルにしておくと・・・\n",
        "  * 高次元の特徴量のいずれについても・・・\n",
        "  * それが低次元空間においてちゃんと表現されてくる可能性が高まる。"
      ],
      "metadata": {
        "id": "jI-ML315VUxY"
      },
      "id": "jI-ML315VUxY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0d4d86e",
      "metadata": {
        "id": "b0d4d86e"
      },
      "outputs": [],
      "source": [
        "def training(model, optimizer, sparsity=0.0, num_epochs=100000, num_data=10000, batch_size=100):\n",
        "    dim_n = model.dim_n\n",
        "    loss_weights = torch.pow(0.7, torch.arange(dim_n).float())\n",
        "    print(f'Dimension of input: {dim_n}')\n",
        "    print(f'Loss weights: {loss_weights}')\n",
        "\n",
        "    # 高次元の特徴量は少ない個数だけが同時にactiveになるようにする\n",
        "    X = torch.rand(num_data, dim_n) # 一様乱数\n",
        "    zero_mask = (torch.rand_like(X) >= sparsity).float()\n",
        "    X = X * zero_mask\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "    for epoch in range(num_epochs):\n",
        "        x = X[torch.randint(0, num_data, (batch_size,))]\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        x_reconstructed, h = model(x)\n",
        "        loss = ((x_reconstructed - x) ** 2 * loss_weights).mean()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if epoch % 10000 == 0:\n",
        "            print(f'Epoch {epoch}, Loss: {loss.item()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80f85b58",
      "metadata": {
        "id": "80f85b58"
      },
      "outputs": [],
      "source": [
        "def evaluate(model):\n",
        "    with torch.no_grad():\n",
        "        feat_norm = torch.norm(model.W, dim=1).to('cpu').numpy()\n",
        "        print(\"Feature norms:\", feat_norm)\n",
        "        superposition = ((model.W @ model.W.t()) ** 2 * (1.0 - torch.eye(model.dim_n))).sum(dim=1)\n",
        "        print(\"Superposition:\", superposition)\n",
        "        return feat_norm, superposition.to('cpu').numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf81b693",
      "metadata": {
        "id": "bf81b693"
      },
      "outputs": [],
      "source": [
        "def visualize(feature_norm, superposition):\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(10, 6), gridspec_kw={'width_ratios': [4, 0.2]})\n",
        "    y_pos = range(len(feature_norm))\n",
        "    colors = plt.cm.viridis(superposition)\n",
        "    ax[0].barh(y_pos[::-1], feature_norm, color=colors)\n",
        "    ax[0].set_yticks(y_pos)\n",
        "    ax[0].set_yticklabels([f'Feature {i}' for i in range(len(feature_norm) - 1, -1, -1)])\n",
        "    ax[0].set_xlabel('Feature Norm')\n",
        "    ax[0].set_title('Feature Norms and Superposition')\n",
        "    sm = plt.cm.ScalarMappable(cmap='viridis', norm=plt.Normalize(vmin=0, vmax=1))\n",
        "    sm.set_array([])\n",
        "    cbar = ax[1].figure.colorbar(sm, cax=ax[1])\n",
        "    cbar.set_label('Superposition')\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ca7e20d",
      "metadata": {
        "id": "4ca7e20d"
      },
      "outputs": [],
      "source": [
        "dim_n = 10\n",
        "dim_m = 2\n",
        "\n",
        "model = SuperpositionModel(dim_n, dim_m)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "training(model, optimizer, sparsity=0.99, num_data=10000, batch_size=100)\n",
        "feature_norm, superposition = evaluate(model)\n",
        "visualize(feature_norm, superposition)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a2f1ff8",
      "metadata": {
        "id": "0a2f1ff8"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "wf = ax.imshow((model.W @ model.W.t()).detach().to('cpu').numpy(), aspect=1, cmap='viridis')\n",
        "ax.set_title('Inner Product Matrix')\n",
        "ax.set_xticks([])\n",
        "ax.set_yticks([])\n",
        "\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"7%\", pad=\"5%\")\n",
        "cb1 = fig.colorbar(wf, cax=cax)\n",
        "\n",
        "ax_bias = divider.append_axes(\"right\", 1.2, pad=0.5, sharey=ax)\n",
        "bf = ax_bias.imshow(model.b.detach().to('cpu').numpy().reshape(-1,1), aspect=1, cmap='inferno')\n",
        "ax_bias.set_title('Bias')\n",
        "ax_bias.set_xticks([])\n",
        "ax_bias.set_yticks([])\n",
        "\n",
        "cax = divider.append_axes(\"right\", size=\"7%\", pad=0)\n",
        "cb1 = fig.colorbar(bf, cax=cax)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c491d502",
      "metadata": {
        "id": "c491d502"
      },
      "outputs": [],
      "source": [
        "# plot the features in 2D space as arrows\n",
        "W_cpu = model.W.detach().to('cpu').numpy()\n",
        "origin = np.zeros((dim_n, 2))\n",
        "plt.quiver(*origin.T, W_cpu[:, 0], W_cpu[:, 1], angles='xy', scale_units='xy', scale=1)\n",
        "plt.xlim(-3, 3)\n",
        "plt.ylim(-3, 3)\n",
        "plt.xlabel('Dimension 1')\n",
        "plt.ylabel('Dimension 2')\n",
        "plt.title('Features in 2D Space')\n",
        "plt.grid()\n",
        "plt.gca().set_aspect('equal')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9759052",
      "metadata": {
        "id": "c9759052"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}