{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course2025-nlp/blob/main/08_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hx2zN0IvyqF"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EecUGZKspEal"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
        "\n",
        "\n",
        "from datasets import load_dataset, DatasetDict\n",
        "from tokenizers import Tokenizer, normalizers\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.normalizers import NFD, Lowercase, StripAccents\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(0)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7p6LtyekseI"
      },
      "outputs": [],
      "source": [
        "ag_news_label = { 0: \"World\", 1: \"Sports\", 2: \"Business\", 3: \"Sci/Tec\" }\n",
        "\n",
        "ds = load_dataset(\"ag_news\")\n",
        "\n",
        "train_valid = ds[\"train\"].train_test_split(test_size=0.05)\n",
        "\n",
        "ds = DatasetDict({\n",
        "    \"train\": train_valid[\"train\"],\n",
        "    \"valid\": train_valid[\"test\"],\n",
        "    \"test\": ds[\"test\"],\n",
        "})\n",
        "\n",
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdtZhLnpF5Gs"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
        "tokenizer.normalizer = normalizers.Sequence([NFD(), Lowercase(), StripAccents()])\n",
        "tokenizer.pre_tokenizer = Whitespace()\n",
        "\n",
        "# padding用トークンのIDを0にするため、special_tokensで先に登録しておく\n",
        "trainer = BpeTrainer(special_tokens=[\"[PAD]\", \"[UNK]\"], vocab_size=30_000)\n",
        "tokenizer.train_from_iterator(ds[\"train\"][\"text\"], trainer=trainer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VS_Q39gJZMOJ"
      },
      "outputs": [],
      "source": [
        "#save_dir = \"/content/drive/MyDrive/2025courses/nlp\"\n",
        "save_dir = \"./\"\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "tokenizer.save(os.path.join(save_dir, \"my-tokenizer.json\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKmppVVRRj0e"
      },
      "outputs": [],
      "source": [
        "padding_value = tokenizer.token_to_id(\"[PAD]\")\n",
        "\n",
        "def collate_padded_batch(batch):\n",
        "  label_list, text_list = [], []\n",
        "  for instance in batch:\n",
        "    _label, _text = instance[\"label\"], instance[\"text\"]\n",
        "    label_list.append(_label)\n",
        "    text_list.append(_text)\n",
        "  labels = torch.tensor(label_list, dtype=torch.int64)\n",
        "  sequences_list = tokenizer.encode_batch(text_list)\n",
        "  token_ids = [torch.tensor(encoded.ids, dtype=torch.int64) for encoded in sequences_list]\n",
        "  padded_sequences = pad_sequence(token_ids, batch_first=True, padding_value=padding_value)\n",
        "  lengths = torch.tensor([len(ids) for ids in token_ids], dtype=torch.int64)\n",
        "  return labels.to(device), padded_sequences.to(device), lengths.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQ-6jH0h4E-1"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    ds[\"train\"], batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_padded_batch\n",
        ")\n",
        "valid_dataloader = DataLoader(\n",
        "    ds[\"valid\"], batch_size=BATCH_SIZE, collate_fn=collate_padded_batch\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    ds[\"test\"], batch_size=BATCH_SIZE, collate_fn=collate_padded_batch\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRJysWR_r9cW"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class TextClassificationModel(nn.Module):\n",
        "  def __init__(self, vocab_size, embed_dim, num_class):\n",
        "    super(TextClassificationModel, self).__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embed_dim, sparse=False)\n",
        "    self.rnn = nn.GRU(embed_dim, embed_dim, num_layers=5, batch_first=True)\n",
        "    self.fc = nn.Linear(embed_dim, num_class)\n",
        "\n",
        "  # forward pass\n",
        "  def forward(self, text, lengths):\n",
        "    embeded = self.embedding(text)\n",
        "    packed_input = pack_padded_sequence(embeded, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
        "    rnn_out, h_n = self.rnn(packed_input)\n",
        "    out = self.fc(h_n[-1])\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4kpm5Ie7tMN"
      },
      "outputs": [],
      "source": [
        "num_class = len(set([label for label in ds[\"train\"][\"label\"]]))\n",
        "vocab_size = tokenizer.get_vocab_size()\n",
        "print(f\"Vocab size: {vocab_size}, num_class: {num_class}\")\n",
        "\n",
        "emsize = 64 # 埋め込みベクトルの次元 (これは自分で決める)\n",
        "print(f\"Embedding size: {emsize}\")\n",
        "\n",
        "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MQqD69DRj0f"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "epochs = 20\n",
        "learning_rate = 1e-4\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeGMjdPd7dXM"
      },
      "outputs": [],
      "source": [
        "def train(dataloader):\n",
        "  model.train()\n",
        "  total_acc, total_count = 0, 0\n",
        "  log_interval = 500 # ログ情報を表示する間隔\n",
        "  start_time = time.time()\n",
        "\n",
        "  for idx, (label, text, lengths) in enumerate(dataloader):\n",
        "    optimizer.zero_grad()\n",
        "    predicted_label = model(text, lengths)\n",
        "    loss = criterion(predicted_label, label)\n",
        "    loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
        "    optimizer.step()\n",
        "    total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "    total_count += label.size(0)\n",
        "    if idx % log_interval == 0 and idx > 0:\n",
        "      elapsed = time.time() - start_time\n",
        "      print(\n",
        "          f\"||| {idx:5d}/{len(dataloader):5d} batches | \"\n",
        "          f\"time: {elapsed:5.2f}s | \"\n",
        "          f\"accuracy {total_acc / total_count:8.3f}\"\n",
        "      )\n",
        "      total_acc, total_count = 0, 0\n",
        "      start_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JEgh9O3sAPj"
      },
      "outputs": [],
      "source": [
        "def evaluate(dataloader):\n",
        "  model.eval()\n",
        "  total_acc, total_count = 0, 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for idx, (label, text, lengths) in enumerate(dataloader):\n",
        "      predicted_label = model(text, lengths)\n",
        "      loss = criterion(predicted_label, label)\n",
        "      total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "      total_count += label.size(0)\n",
        "  return total_acc / total_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vixuo6u2r__K"
      },
      "outputs": [],
      "source": [
        "total_accu = None\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  epoch_start_time = time.time()\n",
        "  train(train_dataloader)\n",
        "  accu_val = evaluate(valid_dataloader)\n",
        "  if total_accu is not None and total_accu > accu_val:\n",
        "    # 検証データの正解率が前のエポックより下がったらスケジューラを動かす\n",
        "    scheduler.step()\n",
        "  else:\n",
        "    total_accu = accu_val\n",
        "  print(\"-\" * 59)\n",
        "  elapsed = time.time() - epoch_start_time\n",
        "  print(\n",
        "      f\"| end of epoch {epoch+1:3d} | \"\n",
        "      f\"time: {elapsed:5.2f}s | \"\n",
        "      f\"lr = {optimizer.param_groups[0]['lr']:.3e} | \"\n",
        "      f\"validation accuracy {accu_val:8.3f}\"\n",
        "  )\n",
        "  print(\"-\" * 82)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ShRmR9Yv-j8"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), os.path.join(save_dir, \"my-model.pt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nAP4f20wDzn"
      },
      "outputs": [],
      "source": [
        "model = TextClassificationModel(vocab_size, emsize, num_class)\n",
        "model.load_state_dict(torch.load(os.path.join(save_dir, \"my-model.pt\"), weights_only=True))\n",
        "model.to(device)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o45KtyPZsF68"
      },
      "outputs": [],
      "source": [
        "print(\"Checking the results of test dataset...\")\n",
        "accu_test = evaluate(test_dataloader)\n",
        "print(f\"test accuracy {accu_test:8.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FMoLIJ5sF3S"
      },
      "outputs": [],
      "source": [
        "def predict(text):\n",
        "  with torch.no_grad():\n",
        "    text = torch.tensor([tokenizer.encode(text).ids]).to(device)\n",
        "    lengths = torch.tensor([text.size(1)]).to(device)\n",
        "    output = model(text, lengths)\n",
        "    return output.argmax(1).item()\n",
        "\n",
        "\n",
        "ex_text_str = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\\n",
        "    enduring the season’s worst weather conditions on Sunday at The \\\n",
        "    Open on his way to a closing 75 at Royal Portrush, which \\\n",
        "    considering the wind and the rain was a respectable showing. \\\n",
        "    Thursday’s first round at the WGC-FedEx St. Jude Invitational \\\n",
        "    was another story. With temperatures in the mid-80s and hardly any \\\n",
        "    wind, the Spaniard was 13 strokes better in a flawless round. \\\n",
        "    Thanks to his best putting performance on the PGA Tour, Rahm \\\n",
        "    finished with an 8-under 62 for a three-stroke lead, which \\\n",
        "    was even more impressive considering he’d never played the \\\n",
        "    front nine at TPC Southwind.\"\n",
        "\n",
        "print(\"This is a {} news\".format(ag_news_label[predict(ex_text_str)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-LBWJ0JRj0g"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}